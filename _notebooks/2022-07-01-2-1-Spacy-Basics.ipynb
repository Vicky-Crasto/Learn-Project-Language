{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4924ff8c",
   "metadata": {},
   "source": [
    "# 2.1 Spacy Basics\n",
    "\n",
    "> The post explains the basics of Spacy library used for NLP\n",
    "\n",
    "- toc : true\n",
    "- badges : false\n",
    "- comments : false\n",
    "- categories : [Spacy,NLP-Chapter2]\n",
    "- image : false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440ac6bf",
   "metadata": {},
   "source": [
    "## Installation and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6d6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b9b38b",
   "metadata": {},
   "source": [
    "### Downloading spacy vocab library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc443537",
   "metadata": {},
   "source": [
    "### Loading Spacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49860674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e549d",
   "metadata": {},
   "source": [
    "**Creating a doc object and printing the different components of the token**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f8a693e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Tesla       NOUN      nsubj\n",
      "        is        AUX        aux\n",
      "   looking       VERB       ROOT\n",
      "        at        ADP       prep\n",
      "    buying       VERB      pcomp\n",
      "      U.S.      PROPN   compound\n",
      "   startup       NOUN       dobj\n",
      "       for        ADP       prep\n",
      "         $        SYM   quantmod\n",
      "         6        NUM   compound\n",
      "   million        NUM       pobj\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Create a doc object\n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')\n",
    "\n",
    "### Printing each token seperately\n",
    "for token in doc:\n",
    "    print(f'{token.text:>{10}} {token.pos_:>{10}} {token.dep_:>{10}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a15db4f",
   "metadata": {},
   "source": [
    "## Understanding the spacy pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f65265c",
   "metadata": {},
   "source": [
    "When we run `nlp`, our text enters a *processing pipeline* that first breaks down the text and then performs a series of operations to tag, parse and describe the data.   Image source: https://spacy.io/usage/spacy-101#pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d2f67d",
   "metadata": {},
   "source": [
    "<img src=\"/ghtop_images/pipeline1.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5b24dd",
   "metadata": {},
   "source": [
    "<img src=\"/ghtop_images/pipeline2.PNG\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a5c1b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x23264bfa220>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x23264bfae80>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x23264a554a0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x23264cb5780>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x23264cc8780>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x23264a55350>)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5efef684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ebe893",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0220056",
   "metadata": {},
   "source": [
    "Tokenization is breaking the raw text into small chunks. Tokenization breaks the raw text into words, sentences called tokens. These tokens help in understanding the context or developing the model for the NLP. The tokenization helps in interpreting the meaning of the text by analyzing the sequence of the words.\n",
    "\n",
    "\n",
    "*Source: https://towardsdatascience.com/tokenization-for-natural-language-processing-a179a891bad4s*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "870ef4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Apple      PROPN      nsubj\n",
      "        is        AUX        aux\n",
      "       n't       PART        neg\n",
      "                SPACE        dep\n",
      "   looking       VERB       ROOT\n",
      "      into        ADP       prep\n",
      "    buying       VERB      pcomp\n",
      "  startups       NOUN       dobj\n",
      "         .      PUNCT      punct\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"Apple isn't  looking into buying startups.\")\n",
    "for token in doc2:\n",
    "    print(f'{token.text:>{10}} {token.pos_:>{10}} {token.dep_:>{10}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b2c37f",
   "metadata": {},
   "source": [
    "**Things to take note**\n",
    "\n",
    "- Spacy is able to recognize the root verb and the negation, hence it has split is'nt into two tokens\n",
    "- Spaces and peroid are assigned as tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f350be43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9093fb9",
   "metadata": {},
   "source": [
    "doc2 is spacy object and contains information of each token in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e87a6",
   "metadata": {},
   "source": [
    "## Part of Speech Tagging(POS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f3a10",
   "metadata": {},
   "source": [
    "In the above example we see the output has clearly label Apple as pronoun, looking as a verb etc.These are parts of speech.\n",
    "\n",
    "For a full list of POS Tags visit https://spacy.io/api/annotation#pos-tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c0629a",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1da9bb",
   "metadata": {},
   "source": [
    "We also looked at the syntactic dependencies assigned to each token. `Tesla` is identified as an `nsubj` or the ***nominal subject*** of the sentence.\n",
    "\n",
    "For a full list of Syntactic Dependencies visit https://spacy.io/api/annotation#dependency-parsing\n",
    "<br>A good explanation of typed dependencies can be found [here](https://nlp.stanford.edu/software/dependencies_manual.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0971c347",
   "metadata": {},
   "source": [
    "**Full name of a tag used in spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfa27570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proper noun'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('PROPN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee23ab37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nominal subject'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('nsubj')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0c31a7",
   "metadata": {},
   "source": [
    "## Additional Token Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed6a115",
   "metadata": {},
   "source": [
    "|Tag|Description|doc2[0].tag|\n",
    "|:------|:------:|:------|\n",
    "|`.text`|The original word text<!-- .element: style=\"text-align:left;\" -->|`Tesla`|\n",
    "|`.lemma_`|The base form of the word|`tesla`|\n",
    "|`.pos_`|The simple part-of-speech tag|`PROPN`/`proper noun`|\n",
    "|`.tag_`|The detailed part-of-speech tag|`NNP`/`noun, proper singular`|\n",
    "|`.shape_`|The word shape â€“ capitalization, punctuation, digits|`Xxxxx`|\n",
    "|`.is_alpha`|Is the token an alpha character?|`True`|\n",
    "|`.is_stop`|Is the token part of a stop list, i.e. the most common words of the language?|`False`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8f83af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking\n",
      "look\n"
     ]
    }
   ],
   "source": [
    "## Lemmas ( the base form of the word)\n",
    "\n",
    "print(doc2[4].text)\n",
    "print(doc2[4].lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6feb96e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple: Xxxxx\n",
      "U.S.: X.X.\n"
     ]
    }
   ],
   "source": [
    "### Word Shapes\n",
    "print(doc2[0].text + ': ' + doc2[0].shape_)\n",
    "print(doc[5].text + ': ' + doc[5].shape_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76caa24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c8449",
   "metadata": {},
   "source": [
    "Large Doc objects can be hard to work with at times. A **span** is a slice of Doc object in the form `Doc[start:stop]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acc0acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e6cca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Life is what happens to us while we are making other plans\"\n"
     ]
    }
   ],
   "source": [
    "life_qoute = doc3[16:30]\n",
    "print(life_qoute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0393cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_qoute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e722cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f14a704",
   "metadata": {},
   "source": [
    "Certain tokens inside a Doc object may also receive a \"start of sentence\" tag. While this doesn't immediately build a list of sentences, these tags enable the generation of sentence segments through `Doc.sents`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de35523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "484bd820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "17eb365f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1e01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
