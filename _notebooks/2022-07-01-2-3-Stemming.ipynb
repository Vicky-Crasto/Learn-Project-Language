{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec8cd734",
   "metadata": {},
   "source": [
    "# 2.3 Stemming\n",
    "\n",
    "> The post explains stemming and shows the implementation of Porter stemmer and snowball stemmer in NLTK\n",
    "\n",
    "- toc : true\n",
    "- badges : false\n",
    "- comments : false\n",
    "- categories : [NLTK,stemming,NLP-Chapter-2]\n",
    "- image : false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529d517a",
   "metadata": {},
   "source": [
    "Stemming is the process of removing a part of a word, or reducing a word to its stem or root.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d30b7",
   "metadata": {},
   "source": [
    "## Porter Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9569faba",
   "metadata": {},
   "source": [
    "One of the most common - and effective - stemming tools is [*Porter's Algorithm*](https://tartarus.org/martin/PorterStemmer/) developed by Martin Porter in [1980](https://tartarus.org/martin/PorterStemmer/def.txt). The algorithm employs five phases of word reduction, each with its own set of mapping rules. In the first phase, simple suffix mapping rules are defined, such as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06267d39",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/930/1*EzaepeAsQpa8SyEc1h9lSA.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a56b8b9",
   "metadata": {},
   "source": [
    "From a given set of stemming rules only one rule is applied, based on the longest suffix S1. Thus, `caresses` reduces to `caress` but not `cares`.\n",
    "\n",
    "More sophisticated phases consider the length/complexity of the word before applying a rule. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604c3f4",
   "metadata": {},
   "source": [
    "![](https://miro.medium.com/max/1719/1*2cUR76NeWoPMiFsur0hQtw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6e028a",
   "metadata": {},
   "source": [
    "## Porter stemmer using NLKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21776b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a136b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96eca080",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','running','ran','runs','easily','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34c3bdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run  ---> run\n",
      "runner  ---> runner\n",
      "running  ---> run\n",
      "ran  ---> ran\n",
      "runs  ---> run\n",
      "easily  ---> easili\n",
      "fairly  ---> fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+'  ---> '+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ec551",
   "metadata": {},
   "source": [
    "## Snowball Stemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e40907f",
   "metadata": {},
   "source": [
    "This is somewhat of a misnomer, as Snowball is the name of a stemming language developed by Martin Porter. The algorithm used here is more acurately called the \"English Stemmer\" or \"Porter2 Stemmer\". It offers a slight improvement over the original Porter stemmer, both in logic and speed. Since **nltk** uses the name SnowballStemmer, we'll use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8fbca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# The Snowball Stemmer requires that you pass a language parameter\n",
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4c33a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','running','ran','runs','easily','fairly']\n",
    "# words = ['generous','generation','generously','generate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16c57d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run --> run\n",
      "runner --> runner\n",
      "running --> run\n",
      "ran --> ran\n",
      "runs --> run\n",
      "easily --> easili\n",
      "fairly --> fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+' --> '+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4e7c09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
